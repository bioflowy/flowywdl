import { Logger,logger } from './logger.ts';
import * as WDLError from '../error.ts'
import * as Value from '../value.ts'
import * as Tree from '../tree.ts'
import * as StdLib from '../stdlib.ts'
import * as Env from '../env.ts'
import * as Expr from '../expr.ts'
import * as Type from '../type.ts'
import { expandGlob,walk } from "https://deno.land/std/fs/mod.ts";
import { OutputError, Interrupted, Terminated, RunFailed } from './error.ts';
import {  type TaskContainer } from "./task_container.ts";
import { existsSync, mkdirSync, realPathSync,path, statSync, rmtreeSync, copyFileSync, copyDir, writeFileSync, pathReallyWithin, chmodRplus, strip_leading_whitespace } from "../runtimeutils.ts";
import { linkForce, provisionRunDir, symlinkForce, topsort, writeValuesJson } from "../utils.ts";
import type { Loader } from "./config.ts";
import { PodmanContainer } from "./backend/podman.ts";
export function newTaskContainer2(cfg: Loader, _: Logger, run_id: string, host_dir: string): TaskContainer{
    /**
    Instantiate a TaskContainer from the configured backend, including any necessary global
    initialization.
    */
  return new PodmanContainer(cfg,run_id,host_dir)
}

interface RuntimeValues {
  env?: { [key: string]: string };
  [key: string]: any;
}
type FileOrDirectory = Value.File | Value.Directory
function linkOutputsRelative(
  link1: (a:string,b:string,c:boolean)=>void,
  outputs: Env.Bindings<Value.Base>,
  runDir: string,
  hardlinks: boolean = false
): Env.Bindings<Value.Base> {
  /**
   * link_outputs with [file_io] use_relative_output_paths = true. We organize the links to reflect
   * the generated files' paths relative to their task working directory.
   */
  const linkDestinations: Map<string, string> = new Map();

  function mapPathRelative(v: FileOrDirectory): string {
      const target = v.value
      // TODO impliment download 
      // existsSync(v.value)
      //    ? :
      //    : getDownload(v.value, v instanceof Value.Directory);

      if (target) {
          const realTarget = realPathSync(target);
          let relLink: string | null = null;

          if (pathReallyWithin(target, path.join(runDir, "work"))) {
              // target was generated by current task; use its path relative to the task work dir
              if (!path.basename(runDir).startsWith("download-")) {  // except download tasks
                  relLink = path.relative(
                      realTarget,
                      realPathSync(path.join(runDir, "work"))
                  );
              }
          } else {
              // target is an out/ link generated by a call in the current workflow OR a cached
              // run; use the link's path relative to that out/ dir, which by induction should
              // equal its path relative to the original work/ dir.
              // we need heuristic to find the out/ dir in a task/workflow run directory, since the
              // user's cwd or the task-generated relative path might coincidentally have
              // something named 'out'.
              const matches = [...target.matchAll(/\/out(?=\/)/g)];
              let p: number | null = null;

              for (let i = matches.length - 1; i >= 0; i--) {
                  const pos = matches[i].index!;
                  if (pos && (
                      existsSync(path.join(target.slice(0, pos), "task.log")) ||
                      existsSync(path.join(target.slice(0, pos), "workflow.log"))
                  )) {
                      p = pos;
                      break;
                  }
              }

              if (p !== null && p + 5 < target.length) {
                  relLink = path.relative(target, target.slice(0, p + 5));
              }
          }

          // if neither of the above cases applies, then fall back to just the target basename
          relLink = relLink || path.basename(target);
          const absLink = path.join(runDir, "out", relLink);

          if (linkDestinations.has(absLink) && linkDestinations.get(absLink) !== realTarget) {
              throw new Error(
                  "Output filename collision; to allow this, set" +
                  " [file_io] use_relative_output_paths = false. Affected path: " + absLink
              );
          }

          mkdirSync(path.dirname(absLink), { recursive: true });
          link1(realTarget, absLink, v instanceof Value.Directory);
          linkDestinations.set(absLink, realTarget);
          return absLink;
      }
      return v.value;
  }

  return Value.rewriteEnvPaths(outputs, mapPathRelative);
}

export async function  linkOutputs(
  outputs: Env.Bindings<Value.Base>,
  runDir: string,
  hardlinks: boolean = false,
  useRelativeOutputPaths: boolean = false
): Promise<Env.Bindings<Value.Base>> {
  /**
   * Following a successful run, the output files may be scattered throughout a complex directory
   * tree used for execution. To help navigating this, generate a subdirectory of the run directory
   * containing nicely organized symlinks to the output files, and rewrite File values in the
   * outputs env to use these symlinks.
   */

  async function link1(target: string, link: string, directory: boolean): Promise<void> {
    console.log(`link1 ${target},${link}`)
      if (hardlinks) {
          // TODO: what if target is an input from a different filesystem?
          if (directory) {
              copyDir(target, link)//, { symlinks: true, copyFunction: linkForce });
          } else {
              await linkForce(target, link);
          }
      } else {
          symlinkForce(target, link);
      }
  }

  async function mapPaths(v: Value.Base, dn: string): Promise<Value.Base> {
    console.log(`mapPath v=${Object.getPrototypeOf(v).constructor.name}`)
      if (Value.isFileOrDirectory(v)) {
          let target = v.value as string
          // TODO implements download 
          // existsSync(v.value) 
          //    ?  
          //    : cache.getDownload(v.value, v instanceof Value.Directory);
          
          console.log(`mapPath target=${target},dn=${dn}`)
          if (target) {
              target = realPathSync(target);
              if (!existsSync(target)) {
                  throw new Error('Target path does not exist');
              }
              
              if (!hardlinks && pathReallyWithin(target, path.dirname(runDir))) {
                  // make symlink relative
                  target = path.relative(realPathSync(dn),target);
              }
              
              const link = path.join(dn, path.basename(target.replace(/\/$/, '')));
              mkdirSync(dn);
              console.log(`mkdirSync dn=${dn},link=${link},target=${target}`)
              await link1(target, link, Value.isDirectory(v));
              
              // Drop a dotfile alongside Directory outputs, to inform a program crawling the out/
              // directory without reference to the output types or JSON for whatever reason. It
              // might otherwise have trouble distinguishing Directory outputs among the
              // structured subdirectories we create for compound types.
              if (v instanceof Value.Directory) {
                  writeFileSync(path.join(dn, '.WDL_Directory'), '');
              }
              v.value = link;
          }
      }
      // recurse into compound values
      else if (v instanceof Value.WDLArray && v.value.length) {
          const d = Math.ceil(Math.log10(v.value.length)); // how many digits needed
          for (let i = 0; i < v.value.length; i++) {
              v.value[i] = await mapPaths(v.value[i], path.join(dn, i.toString().padStart(d, '0')));
          }
      }
      else if (v instanceof Value.Map) {
          // create a subdirectory for each key, as long as the key names seem to make reasonable
          // path components; otherwise, treat the dict as a list of its values
          const keysOk = v.value.every(([key]) => 
              /^[-_a-zA-Z0-9][-_a-zA-Z0-9.]*$/.test(String(key).replace(/['"]/g, ''))
          );
          
          const d = Math.ceil(Math.log10(v.value.length));
          const items:[Value.Base,Value.Base][] = []
          let i=0
          for(const [key,value] of v.value){
            const val = await mapPaths(
                key,
                path.join(dn, 
                    keysOk ? String(key).replace(/['"]/g, '') : i.toString().padStart(d, '0'))
            )
            items.push([key,val])
          }
          v.value = items
      }
      else if (v instanceof Value.Pair) {
          v.value = [
              await mapPaths(v.value[0], path.join(dn, 'left')),
              await mapPaths(v.value[1], path.join(dn, 'right'))
          ];
      }
      else if (v instanceof Value.Struct) {
          for (const key in v.value) {
            v.value[key] = await mapPaths(v.value[key], path.join(dn, key));
          }
      }
      return v;
  }

  mkdirSync(path.join(runDir, 'out'), { recursive: false });

  if (useRelativeOutputPaths) {
      return linkOutputsRelative(link1,  outputs, runDir,  hardlinks );
  }
  return await outputs.mapAwait<Value.Base>(async (binding) => {
    const maped = await mapPaths(
        Value.rewritePaths(binding.value, v => v.value), // nop to deep copy
        path.join(runDir, 'out', binding.name)
    )
    return new Env.Binding(binding.name,maped)
  });
}
async function tryTask(
  cfg: Loader,
  task: Tree.Task,
  logger: Logger,
  container: TaskContainer,
  command: string,
): Promise<void> {
  /**
   * Run the task command in the container, retrying up to runtime.preemptible occurrences of
   * Interrupted errors, plus up to runtime.maxRetries occurrences of any error.
   */
  // delay heavy import

  const maxRetries = container.runtimeValues.maxRetries || 0;
  const maxInterruptions = container.runtimeValues.preemptible || 0;
  let retries = 0;
  let interruptions = 0;

  while (true) {

      // copy input files, if needed
      if (cfg.getBoolean("file_io", "copy_input_files") ||
          cfg.getList("file_io", "copy_input_files_for").includes(task.name)) {
          container.copyInputFiles(logger);
      }

      const hostTmpdir = (cfg.getBoolean("file_io", "mount_tmpdir") ||
          cfg.getList("file_io", "mount_tmpdir_for").includes(task.name))
          ? path.join(container.hostWorkDir(), "_miniwdl_tmpdir")
          : null;

      try {
          // start container & run command
          if (hostTmpdir) {
              logger.debug({
                  message: "creating task temp directory",
                  TMPDIR: hostTmpdir
              });
              mkdirSync(hostTmpdir, { mode: 0o770 });
          }

          try {
              await container.run(logger, command);
              return
          } finally {
              if (hostTmpdir) {
                  logger.info({
                      message: "deleting task temp directory",
                      TMPDIR: hostTmpdir
                  });
                  rmtreeSync(hostTmpdir);
              }
              if ("preemptible" in container.runtimeValues &&
                  cfg.hasOption("task_runtime", "_mock_interruptions") &&
                  interruptions < cfg.getInt("task_runtime","_mock_interruptions")) {
                  const error = new Interrupted("mock interruption");
                  error.cause = null;
                  throw error;
              }
          }
      } catch (exn) {
          if (exn instanceof Interrupted && interruptions < maxInterruptions) {
              logger.error({
                  message: "interrupted task will be retried",
                  error: exn.constructor.name,
                  message2: String(exn),
                  prev_interruptions: interruptions,
                  max_interruptions: maxInterruptions
              });
              interruptions += 1;
          } else if (
              !(exn instanceof Terminated) &&
              retries < maxRetries
          ) {
              logger.error({
                  message: "failed task will be retried",
                  message2: String(exn),
                  prev_retries: retries,
                  max_retries: maxRetries
              });
              retries += 1;
          } else {
              throw exn;
          }
          _delete_work(cfg, logger, container, false);
          container.reset(logger);
      }
  }
}
async function evalTaskRuntime(
  cfg: Loader,
  logger: Logger,
  runId: string,
  task: Tree.Task,
  inputs: Env.Bindings<Value.Base>,
  container: TaskContainer,
  env: Env.Bindings<Value.Base>,
  stdlib: StdLib.Base
): Promise<void> {
  // evaluate runtime{} expressions (merged with any configured defaults)
  const runtimeDefaults = cfg.getDict("task_runtime", "defaults");
  if (runId.startsWith("download-")) {
      Object.assign(runtimeDefaults, cfg.getDict("task_runtime", "download_defaults"));
  }

  const runtimeValues: { [key: string]: Value.Base } = {};
  for (const [key, v] of Object.entries(runtimeDefaults)) {
      runtimeValues[key] = Value.fromJson(new Type.Any(), v);
  }

  for (const [key, expr] of Object.entries(task.runtime)) {  // evaluate expressions in source code
      runtimeValues[key] = await expr.eval(env, stdlib);
  }

  for (const b of inputs.enterNamespace("runtime")) {
      runtimeValues[b.name] = b.value;  // input overrides
  }

  logger.debug({
      message: "runtime values",
      ...Object.fromEntries(
          Object.entries(runtimeValues).map(([key, v]) => [key, String(v)])
      )
  });

  // have container implementation validate & postprocess into container.runtime_values
  container.processRuntime(logger, runtimeValues);
  if (container.runtimeValues) {
      logger.info({
          message: "effective runtime",
          ...container.runtimeValues
      });
  }

  // add any configured overrides for in-container environment variables
  container.runtimeValues.env = container.runtimeValues.env || {};
  const envVarsOverride: { [key: string]: string } = {};
  const envVarsSkipped: string[] = [];

  for (const [evName, evValue] of Object.entries(cfg.getDict("task_runtime","env"))) {
      if (evValue === null) {
            const envValue = Deno.env.get(evName)
            if(envValue!==undefined){
                envVarsOverride[evName] = envValue;
            }else{
                envVarsSkipped.push(evName);
            }
      } else {
          envVarsOverride[evName] = String(evValue);
      }
  }

  if (envVarsSkipped.length) {
      logger.warn({
          message: "skipping pass-through of undefined environment variable(s)",
          names: envVarsSkipped
      });
  }

  if (cfg.getBoolean("file_io", "mount_tmpdir") || 
      cfg.getList("file_io", "mount_tmpdir_for").includes(task.name)) {
      envVarsOverride["TMPDIR"] = path.join(
          container.containerDir,
          "work",
          "_miniwdl_tmpdir"
      );
  }

  if (Object.keys(envVarsOverride).length) {
      // usually don't dump values into log, as they may often be auth tokens
      logger.info({
          message: "overriding environment variables (portability warning)",
          names: Object.keys(envVarsOverride)
      });
      logger.debug({
          message: "overriding environment variables (portability warning)",
          ...envVarsOverride
      });
      Object.assign(container.runtimeValues["env"], envVarsOverride);
  }

  // process decls with "env" decorator (EXPERIMENTAL)
  const envDecls: { [key: string]: any } = {};
  for (const decl of [...(task.inputs || []), ...task.postinputs]) {
      if (decl.decor["env"]  === true) {
          if (Object.keys(envDecls).length === 0) {
              logger.warn(
                  "task env declarations are an experimental feature, subject to change"
              );
          }
          const v = env.get(decl.name);
          if (v instanceof Value.String || v instanceof Value.File || v instanceof Value.Directory) {
              envDecls[decl.name] = v.value;
          } else if(v){
              envDecls[decl.name] = JSON.stringify(v.json);
          }
      }
  }
  Object.assign(container.runtimeValues["env"], envDecls);

  const unusedKeys = Object.keys(runtimeValues).filter(
      key => !["memory", "docker", "container"].includes(key) && 
             !(key in container.runtimeValues)
  );
  
  if (unusedKeys.length) {
      logger.warn({
          message: "ignored runtime settings",
          keys: unusedKeys
      });
  }
}
export function warnOutputBasenameCollisions(
    logger: Logger,
    outputs: Env.Bindings<Value.Base>
) {
    const targetsByBasename: Map<string, Set<string>> = new Map();

    const walker = (v: Value.File | Value.Directory): string => {
        let target = v.value;
        if (existsSync(target)) {
            target = realPathSync(target);
        }
        const basename = path.basename(target);
        
        if (!targetsByBasename.has(basename)) {
            targetsByBasename.set(basename, new Set());
        }
        targetsByBasename.get(basename)!.add(target);
        return v.value;
    };

    Value.rewriteEnvPaths(outputs, walker);

    const collisions = Array.from(targetsByBasename.entries())
        .filter(([_, targets]) => targets.size > 1)
        .map(([basename, _]) => basename);

    if (collisions.length > 0) {
        logger.warn(
                "multiple output files share the same basename; while miniwdl supports this," +
                " consider modifying WDL to ensure distinct output basenames",
                { basenames: collisions }
        );
    }
}
export async function downloadInputFiles(
    cfg: Loader,
    logger: Logger,
    logger_prefix: string[],
    run_dir: string,
    inputs: Env.Bindings<Value.Base>,
): Promise<Env.Bindings<Value.Base>> {
    /**
     * Find all File & Directory input values that are downloadable URIs (including any nested within
     * compound values). Download them to some location under run_dir and return a copy of the inputs
     * with the URI values replaced by the downloaded paths.
     */
    let downloads = 0;
    let download_bytes = 0;
    let cached_hits = 0;

    const rewriter = (v: Value.Directory | Value.File): string => {
        const directory = v instanceof Value.Directory;
        const uri = v.value;
        // TODO implement download
        // if (await downloadable(cfg, uri, { directory })) {
        //     logger.info(_(`download input ${directory ? 'directory' : 'file'}`, { uri }));
            
        //     const [cached, filename] = await download(
        //         cfg,
        //         logger,
        //         uri,
        //         {
        //             directory,
        //             run_dir: path.join(run_dir, "download", downloads.toString(), "."),
        //             logger_prefix: [...logger_prefix, `download${downloads}`]
        //         }
        //     );

        //     if (cached) {
        //         cached_hits++;
        //     } else {
        //         const sz = await pathsize(filename);
        //         logger.info(_("downloaded input", { uri, path: filename, bytes: sz }));
        //         downloads++;
        //         download_bytes += sz;
        //     }
        //     return filename;
        // }
        return uri;
    };

    const ans = await Value.rewriteEnvPaths(inputs, rewriter);
    
    if (downloads || cached_hits) {
        logger.info(
            "processed input URIs", {
                downloaded: downloads,
                downloaded_bytes: download_bytes,
                cached: cached_hits,
            }
        );
    }
    return ans;
}

export function addDownloadableDefaults(
    cfg: Loader,
    available_inputs: Env.Bindings<Tree.Decl>,
    inputs: Env.Bindings<Value.Base>
): Env.Bindings<Value.Base> {
    /**
     * Look for available File/Directory inputs that default to a string constant appearing to be a
     * downloadable URI. For each one, add a binding for that default to the user-supplied inputs (if
     * not already overridden in them).
     *
     * This is to trigger download of the default URIs even though we otherwise don't evaluate input
     * declarations until after processing downloads.
     */
    let ans = inputs;

    for (const b of available_inputs) {
        if (
            (b.value.type instanceof Type.File || b.value.type instanceof Type.Directory) &&
            !ans.hasBinding(b.name) &&
            b.value.expr instanceof Expr.String
        ) {
            const directory = b.value.type instanceof Type.Directory;
            const maybe_uri = b.value.expr.literal;
            
            if (maybe_uri) {
                const v = directory
                    ? new Value.Directory(maybe_uri.value as string, b.value.expr)
                    : new Value.File(maybe_uri.value as string, b.value.expr);
                ans = ans.bind(b.name, v);
            }
        }
    }
    return ans;
}
function isFileNotFoundError(err:any):boolean {
    return false
}
export async function runLocalTask(
  cfg: Loader,
  task: Tree.Task,
  inputs: Env.Bindings<Value.Base>,
  runId: string | null = null,
  runDir2: string | null = null,
  loggerPrefix: string[] | null = null,
  _runIdStack: string[] | null = null,
): Promise<[string, Env.Bindings<Value.Base>]> {
  /**
   * Run a task locally.
   *
   * Inputs shall have been typechecked already. File inputs are presumed to be local POSIX file
   * paths that can be mounted into a container.
   *
   * @param runId unique ID for the run, defaults to workflow name
   * @param runDir directory under which to create a timestamp-named subdirectory for this run
   *               (defaults to current working directory).
   *               If the final path component is ".", then operate in run_dir directly.
   */
  
  // delay heavy import
  const newTaskContainer = newTaskContainer2;

  _runIdStack = _runIdStack || [];
  runId = runId || task.name;
  loggerPrefix = (loggerPrefix || ["wdl"]).concat(["t:" + runId]);
  
      // provision run directory and log file
      const runDir = await provisionRunDir(task.name, runDir2, !_runIdStack);
      const logfile = path.join(runDir, "task.log");
      logger.info(
          {
              message: "task setup",
              name: task.name,
              source: task.pos.uri,
              line: task.pos.line,
              column: task.pos.column,
              dir: runDir,
          }
      );
      writeValuesJson(inputs, path.join(runDir, "inputs.json"));

      let maybeContainer = null;
      try {
          const cached = inputs //, task.effective_outputs);
          
        //   if (cached !== null) {
        //       // create out/ and outputs.json
        //       const _outputs = linkOutputs(
        //           cached,
        //           runDir,
        //           cfg.getBoolean("file_io","output_hardlinks"),
        //           cfg.getBoolean("file_io","use_relative_output_paths")
        //       );
        //       writeValuesJson(
        //           cached,
        //           path.join(runDir, "outputs.json"),
        //           task.name 
        //       );
        //       logger.info("done (cached)");
        //       return [runDir, cached];
        //   }

          try {

              // download input files, if needed
              const posixInputs = await downloadInputFiles(
                  cfg,
                  logger,
                  loggerPrefix,
                  runDir,
                  addDownloadableDefaults(cfg, task.availableInputs, inputs),
              );

              // create TaskContainer according to configuration
              const container = newTaskContainer(cfg, logger, runId, runDir);
              maybeContainer = container;

              // evaluate input/postinput declarations, including mapping from host to
              // in-container file paths
              const containerEnv = await _evalTaskInputs(logger, task, posixInputs, container);

              // evaluate runtime fields
              const stdlib = new InputStdLib(task.effective_wdl_version, logger, container);
              await evalTaskRuntime(
                  cfg,
                  logger,
                  runId,
                  task,
                  posixInputs,
                  container,
                  containerEnv,
                  stdlib
              );

              // interpolate command
              const placeholderRe = new RegExp(
                  cfg.get("task_runtime","placeholder_regex"),"g"
              );
              Expr.setPlaceholderRegex(placeholderRe)
              const command = strip_leading_whitespace(
                  (await task.command.eval(containerEnv, stdlib)).value as string
              )[1];
              Expr.setPlaceholderRegex(undefined)
              logger.debug({ message: "command", command: command.trim() });

              // process command & container through plugins

              // start container & run command (and retry if needed)
              await tryTask(cfg, task, logger, container, command);

              // evaluate output declarations
              let outputs = await evalTaskOutputs(logger, runId, task, containerEnv, container);

              // create output_links
              outputs = await linkOutputs(
                  outputs,
                  runDir,
                  cfg.getBoolean("file_io","output_hardlinks"),
                  cfg.getBoolean("file_io","use_relative_output_paths")
              );

              // process outputs through plugins

              // clean up, if so configured, and make sure output files will be accessible to
              // downstream tasks
              _delete_work(cfg, logger, container, true);
              await chmodRplus(runDir, 0o660, 0o770);
              warnOutputBasenameCollisions(logger, outputs);

              // write outputs.json
              writeValuesJson(
                  outputs,
                  path.join(runDir, "outputs.json"),
                  task.name
              );
              logger.info("done");
              return [runDir, outputs];
          } finally {
          }
      } catch (exn) {
        if(exn instanceof Error){
            logger.error("error",exn)
        }
          const wrapper = new RunFailed(task, runId, runDir);
          const logmsg = {
              message: String(wrapper),
              dir: runDir,
            //   ...error_json(
            //       exn,
            //       { traceback: !(exn instanceof WDLError.RuntimeError) ? exn.s : null }
            //   )
          };
          
          if (exn instanceof Terminated && exn.quiet) {
              logger.debug(logmsg);
          } else {
              logger.error(logmsg);
          }

          try {
              writeFileSync(
                  path.join(runDir, "error.json"),
                  JSON.stringify(
                    {
                        wrapper,
                              cause: exn,
                              traceback: !(exn instanceof WDLError.RuntimeError) ? exn : null
                          }
                      ),
                  )
          } catch (exn2) {
              logger.critical({
                  message: "failed to write error.json",
                  dir: runDir,
                  message2: String(exn2)
              });
          }

          try {
              if (maybeContainer) {
                  _delete_work(cfg, logger, maybeContainer, false);
              }
          } catch (exn2) {
              logger.error({
                  message: "delete_work also failed",
                  exception: String(exn2)
              });
          }
          throw wrapper;
      }
}
function _delete_work(
  cfg: Loader,
  logger: Logger,
  container: TaskContainer | null,
  success: boolean,
){
  const opt = cfg.get("file_io","delete_work")?.trim().toLowerCase()
  if( container && (
      opt == "always" || (success && opt == "success") || (! success && opt == "failure")
  )){
      if( success && !cfg.getBoolean("file_io", "output_hardlinks")){
          logger.warn(
              "ignoring configuration [file_io] delete_work because it requires also output_hardlinks = true"
          )
          return
        }
      container.delete_work(logger, !success)
    }
}
/**
 * traverse output directory to check that all symlinks are relative & resolve inside the dir
 */
async function _check_directory(host_path: string, output_name: string): Promise<void> {
    try {
        // walkのオプションでfollowSymlinksをfalseに設定
        for await (const entry of walk(host_path, { followSymlinks: false })) {
            if (entry.isFile) {
                const fn = entry.path;
                
                // ファイルがシンボリックリンクかチェック
                const fileInfo = await Deno.lstat(fn);
                if (fileInfo.isSymlink) {
                    try {
                        // シンボリックリンクの実体を読み取り
                        const linkTarget = await Deno.readLink(fn);
                        
                        // 次の条件のいずれかを満たす場合はエラー：
                        // 1. リンク先が存在しない
                        // 2. リンクパスが絶対パス
                        // 3. リンク先がホストパスの外にある
                        const linkExists = existsSync(fn);
                        if (!linkExists ||
                            path.isAbsolute(linkTarget) ||
                            !(await pathReallyWithin(fn, host_path))
                        ) {
                            throw new OutputError(
                                `Directory in output ${output_name} contains unusable symlink`
                            );
                        }
                    } catch (error) {
                        if (!(error instanceof OutputError)) {
                            throw new OutputError(
                                `Directory in output ${output_name} contains unusable symlink`
                            );
                        }
                        throw error;
                    }
                }
            }
        }
    } catch (error) {
        if (error instanceof Deno.errors.PermissionDenied) {
            throw error;
        }
        throw new OutputError(
            `Failed to check directory ${output_name}: ${error}`
        );
    }
}
/**
* Log notices about extraneous keys found in struct initialization from JSON/Map/Object
*/
function _warn_struct_extra(
    logger: Logger, 
    decl_name: string,
    v: Value.Base,
    warned_keys: Set<string> = new Set()
 ): void {
    if (v instanceof Value.Struct && v.extra) {
        const extra_keys = new Set(
            Object.keys(v.extra).filter(k => !k.startsWith("#"))
        );
 
        const new_keys = new Set(
            Array.from(extra_keys).filter(k => !warned_keys.has(k))
        );
 
        if (new_keys.size > 0) {
            logger.info(
                "extraneous keys in struct initializer", {
                    decl: decl_name,
                    struct: String(v.type),
                    extra_keys: Array.from(extra_keys)
                }
            );
            
            // warned_keysを更新
            new_keys.forEach(key => warned_keys.add(key));
        }
    }
 
    // 子要素に対して再帰的に処理
    for (const ch of v.children) {
        _warn_struct_extra(logger, decl_name, ch, warned_keys);
    }
 }
async function evalTaskOutputs(
  logger: Logger,
  runId: string,
  task: Tree.Task,
  env: Env.Bindings<Value.Base>,
  container: TaskContainer
) {
  const stdoutFile = path.join(container.hostDir, "stdout.txt");
  try {
      if (statSync(stdoutFile).size > 0 && !runId.startsWith("download-")) {
          // If the task produced nonempty stdout that isn't used in the WDL outputs, generate a
          // courtesy log message directing user where to find it
          let stdoutUsed = false;
          const exprStack = task.outputs.map((outp: any) => outp.expr);
          
          while (exprStack.length > 0) {
              const expr = exprStack.pop();
              if (!(expr instanceof Expr.Base)) {
                  throw new Error("Invalid expression type");
              }
              if (expr instanceof Expr.Apply && expr.function_name === "stdout") {
                  stdoutUsed = true;
              } else {
                  exprStack.push(...expr.children);
              }
          }
          
          if (!stdoutUsed) {
              logger.info({
                  message: "command stdout unused; consider output `File cmd_out = stdout()`" +
                          " or redirect command to stderr log >&2",
                  stdout_file: stdoutFile
              });
          }
      }
  } catch (error) {
      if (!isFileNotFoundError(error)) throw error;
  }

  // Helpers to rewrite File/Directory from in-container paths to host paths
  // First pass -- convert nonexistent output paths to null
  function rewriter1(v: any, outputName: string): string | null {
      let containerPath = v.value;
      if (v instanceof Value.Directory && !containerPath.endsWith("/")) {
          containerPath += "/";
      }
      if (container.hostPath(containerPath) === null) {
          logger.warn({
              message: "output path not found in container (error unless declared type is optional)",
              output: outputName,
              path: containerPath
          });
          return null;
      }
      return v.value;
  }

  // Second pass -- convert in-container paths to host paths
  function rewriter2(v: any, outputName: string): string | null {
      let containerPath = v.value;
      if (v instanceof Value.Directory && !containerPath.endsWith("/")) {
          containerPath += "/";
      }
      const hostPath = container.hostPath(containerPath);
      if (hostPath === null) {
          throw new Error("Host path should not be null at this point");
      }
      
      if (v instanceof Value.Directory) {
          let finalHostPath = hostPath.endsWith("/") ? hostPath.slice(0, -1) : hostPath;
          _check_directory(finalHostPath, outputName);
          logger.debug({
              message: "output dir",
              container: containerPath,
              host: finalHostPath
          });
          return finalHostPath;
      } else {
          logger.debug({
              message: "output file",
              container: containerPath,
              host: hostPath
          });
          return hostPath;
      }
  }

    const stdlib = new OutputStdLib(task.effective_wdl_version, logger, container);
    let outputs = new Env.Bindings<Value.Base>();

    for (const decl of task.outputs) {
      if (!decl.expr) {
          throw new Error("Declaration expression is required");
      }

      let v;
      try {
        const rslt = await decl.expr.eval(env, stdlib)
        logger.info(`rslt=${rslt} constructorname=${Object.getPrototypeOf(rslt).constructor.name}`)
          v = rslt.coerce(decl.type);
          logger.info(`v=${v} constructorname=${Object.getPrototypeOf(v).constructor.name}`)
        } catch (error) {
          if (error instanceof WDLError.RuntimeError) {
              (error as any).job_id = decl.workflowNodeId;
              throw error;
          } else {
              const exn2 = new WDLError.EvalError(decl, String(error));
              (exn2 as any).job_id = decl.workflowNodeId;
              throw exn2;
          }
      }

      _warn_struct_extra(logger, decl.name, v);
      const vj = JSON.stringify(v.json);
      logger.info({
          message: "output",
          name: decl.name,
          value: vj.length < 4096 ? v.json : "(((large)))"
      });

      // Now, a delicate sequence for postprocessing File outputs (including Files nested within
      // compound values)

      // First convert nonexistent paths to null, and bind this in the environment for
      // evaluating subsequent output expressions.
      v = Value.rewritePaths(v, (w: any) => rewriter1(w, decl.name));
      env = env.bind(decl.name, v);

      // check if any nonexistent paths were provided for (non-optional) File/Directory types
      // Value.Null.coerce has a special behavior for us to raise FileNotFoundError for a
      // non-optional File/Directory type.
      try {
          v = v.coerce(decl.type);
      } catch (error) {
          if (isFileNotFoundError(error)) {
              const err = new OutputError("File/Directory path not found in task output " + decl.name);
              (err as any).job_id = decl.workflowNodeId;
              throw err;
          }
          throw error;
      }

      // Rewrite in-container paths to host paths
      v = Value.rewritePaths(v, (w: any) => rewriter2(w, decl.name));
      outputs = outputs.bind(decl.name, v);
  }

  return outputs;
}
function _warnInputBasenameCollisions(logger: Logger, container: TaskContainer): void {
  // Count occurrences of each basename
  const basenames = new Map<string, number>();
  
  for (const p of Object.keys(container.inputPathMapRev)) {
      const basename = path.basename(p.endsWith('/') ? p.slice(0, -1) : p);
      basenames.set(basename, (basenames.get(basename) || 0) + 1);
  }

  // Find collisions (basenames that appear more than once)
  const collisions = Array.from(basenames.entries())
      .filter(([_, count]) => count > 1)
      .map(([name, _]) => name);

  if (collisions.length > 0) {
      logger.warn(
          "mounting input files with colliding basenames in separate container directories", {
              basenames: collisions
          }
      );
  }
}
class _StdLib extends StdLib.Base {
  protected logger: Logger;
  protected container: TaskContainer;
  protected inputs_only: boolean;  // if True then only permit access to input files

  constructor(
      wdl_version: string,
      logger: Logger,
      container: TaskContainer,
      inputs_only: boolean
  ) {
      super(wdl_version,  path.join(container.hostDir, "write_"));
      this.logger = logger;
      this.container = container;
      this.inputs_only = inputs_only;
  }

  protected _devirtualize_filename(filename: string): string {
      // check allowability of reading this file, & map from in-container to host
      const ans = this.container.hostPath(filename, this.inputs_only);
      if (ans === null) {
          throw new OutputError("function was passed non-existent file " + filename);
      }
      this.logger.debug("read_", {
          container: filename,
          host: ans
      });
      return ans;
  }

  protected _virtualize_filename(filename: string): string {
      // register new file with container input_path_map
      this.container.addPaths([filename]);
      this.logger.debug(
          "write_", {
              host: filename,
              container: this.container.inputPathMap[filename]
          }
      );
      this.logger.info("wrote", {
          file: this.container.inputPathMap[filename]
      });
      return this.container.inputPathMap[filename];
  }
}

class InputStdLib extends _StdLib {
  // StdLib for evaluation of task inputs and command
  constructor(
      wdl_version: string,
      logger: Logger,
      container: TaskContainer
  ) {
      super(wdl_version, logger, container, true);
  }
}
/**
 * Get the unique paths of all File & Directory values in the environment. Directory paths will
 * have a trailing '/'.
 */
export function _fspaths(env: Env.Bindings<Value.Base>): Set<string> {
    const ans = new Set<string>();

    const collector = (v: Value.Base): void => {
        if (v instanceof Value.File) {
            if (v.value.endsWith("/")) {
                throw new Error("File path should not end with '/'");
            }
            ans.add(v.value);
        } else if (v instanceof Value.Directory) {
            ans.add(v.value.replace(/\/+$/, "") + "/");
        }
        for (const ch of v.children) {
            collector(ch);
        }
    };

    for (const b of env) {
        collector(b.value);
    }
    return ans;
}
export class OutputStdLib extends _StdLib {
  // StdLib for evaluation of task outputs
  constructor(
      wdl_version: string,
      logger: Logger,
      container: TaskContainer
  ) {
      super(wdl_version, logger, container, false);

      this.stdout = new StdLib.StaticFunction(
          "stdout",
          [],
          new Type.File(),
          () => new Value.File(path.join(this.container.containerDir, "stdout.txt"))
      );

      this.stderr = new StdLib.StaticFunction(
          "stderr",
          [],
          new Type.File(),
          () => new Value.File(path.join(this.container.containerDir, "stderr.txt"))
      );

      const _glob = async (pattern: Value.String, lib: OutputStdLib = this): Promise<Value.WDLArray> => {
          const pat = pattern.coerce(new Type.String()).value;
          if (!pat) {
              throw new OutputError("empty glob() pattern");
          }
          if (typeof pat !== 'string') {
              throw new Error("Expected string pattern");
          }
          if (pat[0] === "/") {
              throw new OutputError("glob() pattern must be relative to task working directory");
          }
          if (pat.startsWith("..") || pat.includes("/..")) {
              throw new OutputError("glob() pattern must not use .. uplevels");
          }

          let normalized_pat = pat;
          if (normalized_pat.startsWith("./")) {
              normalized_pat = normalized_pat.slice(2);
          }

          // glob the host directory
          const globPattern = path.join(lib.container.hostWorkDir(), normalized_pat);
          const host_files = []
          for await (const fn of expandGlob(globPattern)){
            if(fn.isFile){
                host_files.push(path.join(lib.container.hostWorkDir(),fn.name))
            }
          }
          host_files.sort();

          // convert the host filenames to in-container filenames
          const container_files = host_files.map(hf => {
              let dstrip = lib.container.hostWorkDir();
              dstrip += dstrip.endsWith("/") ? "" : "/";
              if (!hf.startsWith(dstrip)) {
                  throw new Error("Unexpected path format");
              }
              return path.join(
                  lib.container.containerDir,
                  "work",
                  hf.slice(dstrip.length)
              );
          });

          return new Value.WDLArray(
              new Type.File(),
              container_files.map(fn => new Value.File(fn))
          );
      };

      this.glob = new StdLib.StaticFunction(
          "glob",
          [new Type.String()],
          new Type.WDLArray(new Type.File()),
          _glob
      );
      this.functions.set("stderr",this.stderr);
      this.functions.set("stdout",this.stdout);
      this.functions.set("glob",this.glob);
  }

  stdout: StdLib.StaticFunction;
  stderr: StdLib.StaticFunction;
  glob: StdLib.StaticFunction;
}
async function  _evalTaskInputs(
  logger: Logger,
  task: Tree.Task,
  posixInputs: Env.Bindings<Value.Base>,
  container: TaskContainer
): Promise<Env.Bindings<Value.Base>> {
  // Preprocess inputs: if None value is supplied for an input declared with a default but without
  // the ? type quantifier, remove the binding entirely so that the default will be used. In
  // contrast, if the input declaration has an -explicitly- optional type, then we'll allow the
  // supplied None to override any default.
  const inputDecls = task.availableInputs;
  posixInputs = posixInputs.filter(
      (b) => !(
          b.value instanceof Value.Null &&
          b.name in inputDecls &&
          inputDecls.get(b.name)?.expr &&
          !inputDecls.get(b.name)?.type.optional
      )
  );

  // Map all the provided input File & Directory paths to in-container paths
  container.addPaths(Array.from(_fspaths(posixInputs)));
  _warnInputBasenameCollisions(logger, container);

  // copy posixInputs with all File & Directory values mapped to their in-container paths
  const mapPaths = (fn: Value.File | Value.Directory): string => {
      let p = fn.value.replace(/\/+$/, "");
      if (fn instanceof Value.Directory) {
          p += "/";
      }
      return container.inputPathMap[p];
  };

  const containerInputs = Value.rewriteEnvPaths(posixInputs, mapPaths);

  // initialize value environment with the inputs
  let containerEnv: Env.Bindings<Value.Base> = new Env.Bindings();
  for (const b of containerInputs) {
      if (!(b instanceof Env.Binding)) {
          throw new Error("Expected Binding instance");
      }
      const v = b.value;
      if (!(v instanceof Value.Base)) {
          throw new Error("Expected Value.Base instance");
      }
      containerEnv = containerEnv.bind(b.name, v);
      const vj = JSON.stringify(v.json);
      logger.info("input", { 
          name: b.name, 
          value: vj.length < 4096 ? v.json : "(((large)))" 
      });
  }

  // collect remaining declarations requiring evaluation
  const declsToEval: Tree.Decl[] = [];
  for (const decl of [...(task.inputs || []), ...(task.postinputs || [])]) {
      if (!containerEnv.hasBinding(decl.name)) {
          declsToEval.push(decl);
      }
  }

  // topsort them according to internal dependencies. prior static validation
  // should have ensured they're acyclic.
  // TODO enable topo sort
  const [declsById, declsAdj] = Tree._decl_dependency_matrix(declsToEval);
  const sortedDecls = topsort(declsAdj).map(did => declsById[did]);
  if (Object.keys(declsById).length !== declsToEval.length) {
      throw new Error("Dependency resolution error");
  }

  // evaluate each declaration in that order
  // note: the write_* functions call container.add_paths as a side-effect
  const stdlib = new InputStdLib(task.effective_wdl_version, logger, container);
  for (const decl of sortedDecls) {
      if (!(decl instanceof Tree.Decl)) {
          throw new Error("Expected Decl instance");
      }
      let v: Value.Base = new Value.Null();
      if (decl.expr) {
          try {
            const rslt = await decl.expr.eval(containerEnv, stdlib)
              v = rslt.coerce(decl.type);
          } catch (exn) {
              if (exn instanceof WDLError.RuntimeError) {
                  (exn as any).job_id = decl.workflowNodeId;
                  throw exn;
              }
              const exn2 = new WDLError.EvalError(decl, String(exn));
              (exn2 as any).job_id = decl.workflowNodeId;
              throw exn2;
          }
      } else {
          if (!decl.type.optional) {
              throw new Error(`Non-optional declaration ${decl.name} has no expression`);
          }
      }
      const vj = JSON.stringify(v.json);
      logger.info("eval", {
          name: decl.name,
          value: vj.length < 4096 ? v.json : "(((large)))"
      });
      containerEnv = containerEnv.bind(decl.name, v);
  }

  return containerEnv;
}