import * as Type from '../type.ts';
import * as Tree from '../tree.ts';
import * as WDLError from '../error.ts';
import * as Env from '../env.ts';
import * as Value from '../value.ts';
import * as StdLib from '../stdlib.ts';
import { logger, type Logger } from "./logger.ts";
import type { Loader } from "./config.ts";
import { existsSync, path, pathReallyWithin } from "../runtimeutils.ts";
import { provisionRunDir, valuesToJson, writeValuesJson } from "../utils.ts";
import { _fspaths, addDownloadableDefaults, downloadInputFiles, linkOutputs, runLocalTask, warnOutputBasenameCollisions } from "./task.ts";

class WorkflowOutputs extends Tree.WorkflowNode {
    /**
     * A no-op workflow node which depends on each ``Decl`` node from the workflow output section. Or,
     * if the workflow is missing the output section, depends on ``Call`` and ``Gather`` nodes for all
     * call outputs.
     * 
     * The workflow state machine tacks this on to the workflow graph to facilitate assembly of the
     * outputs environment.
     */

    private output_node_ids: Set<string>;

    constructor(workflow: Tree.Workflow) {
        super("outputs", workflow.pos);

        this.output_node_ids = new Set<string>();
        if (workflow.outputs.length > 0) {
            for (const node of workflow.outputs) {
                this.output_node_ids.add(node.workflowNodeId);
            }
        } else {
            // no output{} section -- use all top-level Calls and any top-level Gather whose
            // ultimate referee is a Call
            for (const n of workflow.body) {
                if (n instanceof Tree.Call) {
                    this.output_node_ids.add(n.workflowNodeId);
                }
                if (n instanceof Tree.WorkflowSection) {
                    for (const g of Object.values(n.gathers)) {
                        if (g.finalReferee instanceof Tree.Call) {
                            this.output_node_ids.add(g.workflowNodeId);
                        }
                    }
                }
            }
        }
    }

    protected _workflow_node_dependencies(): Iterable<string> {
        return this.output_node_ids;
    }

    public add_to_type_env(
        _struct_types: Env.Bindings<Record<string, Type.Base>>,
        _type_env: Env.Bindings<Type.Base>
    ): Env.Bindings<Type.Base> {
        throw new Error('Not implemented');
    }

}

interface Job {
    id: string;
    node: Tree.WorkflowNode;
    dependencies: Set<string>;
    scatterStack: Array<[string, Env.Binding<Value.Base>]>;
}

type CallInstructions = {
    id: string;
    callee: Tree.Task | Tree.Workflow;
    inputs: Env.Bindings<Value.Base>;
}

/**
 * On-line workflow state machine, suitable for use within a singleton driver process managing
 * in-memory state. The state machine evaluates WDL expressions locally, while instructing the
 * driver when to call tasks/subworkflows. It's agnostic to how/where the driver actually executes
 * each call, just requiring asynchronous notification of call completion along with the outputs.
 */
class StateMachine {
    private _logger: Logger | null = null;
    private loggerId: string;
    runDir: string;
    private valuesToJson: (bindings: Env.Bindings<Value.Base>) => Record<string, unknown>;
    private workflow: Tree.Workflow;
    private inputs: Env.Bindings<Value.Base>;
    private jobs: Map<string, Job>;
    private jobOutputs: Map<string, Env.Bindings<Value.Base>>;
    private finished: Set<string>;
    private running: Set<string>;
    private waiting: Set<string>;

    // File/Directory paths that were either expressly supplied as workflow inputs, or were
    // generated by this workflow execution. By default, these are the only local paths the workflow
    // is allowed to access. (Unless [file_io] allow_any_input = true)
    fspathAllowlist: Set<string>;

    constructor(
        loggerId: string,
        runDir: string,
        workflow: Tree.Workflow,
        inputs: Env.Bindings<Value.Base>
    ) {
        this.loggerId = loggerId;
        this.runDir = runDir;
        this.workflow = workflow;
        this.inputs = inputs;
        this.jobs = new Map();
        this.jobOutputs = new Map();
        this.finished = new Set();
        this.running = new Set();
        this.waiting = new Set();
        this.fspathAllowlist = _fspaths(inputs);

        // Import values_to_json from relative path
        this.valuesToJson = valuesToJson;

        // Preprocess inputs: if None value is supplied for an input declared with a default but
        // without the ? type quantifier, remove the binding entirely so that the default will be
        // used. In contrast, if the input declaration has an -explicitly- optional type, then we'll
        // allow the supplied None to override any default.
        const inputDecls = workflow.availableInputs;
        this.inputs = this.inputs.filter(
            (b) => !(
                b.value instanceof Value.Null &&
                inputDecls.hasBinding(b.name) &&
                inputDecls.get(b.name)?.expr &&
                !inputDecls.get(b.name)?.type.optional
            )
        );

        const workflowNodes = [...(workflow.inputs || []), ...workflow.body, ...(workflow.outputs || [])];
        workflowNodes.push(new WorkflowOutputs(workflow));

        for (const node of workflowNodes) {
            let deps = node.workflowNodeDependencies;
            if (node instanceof Tree.Decl) {
                // strike the dependencies of any decl node whose value is supplied in the inputs
                if (this.inputs.hasBinding(node.name)) {
                    deps = new Set();
                }
            }
            this._schedule({
                id: node.workflowNodeId,
                node: node,
                dependencies: deps,
                scatterStack: []
            });
        }

        // sanity check
        if (!this.jobs.has("outputs")) {
            throw new Error("Missing outputs job");
        }
        const knownJobs = new Set(this.waiting);
        for (const node of workflowNodes) {
            if (node instanceof Tree.WorkflowSection) {
                for (const gather of Object.values(node.gathers)) {
                    knownJobs.add(gather.workflowNodeId);
                }
            }
        }
        for (const job of this.jobs.values()) {
            const unknownDeps = new Set([...job.dependencies].filter(x => !knownJobs.has(x)));
            if (unknownDeps.size > 0) {
                throw new Error(`Unknown dependencies for job ${job.id}: ${[...unknownDeps].join(', ')}`);
            }
        }
    }

    /**
     * Workflow outputs, once the workflow is completely finished. `null` until then.
     * 
     * Warning: be sure to distinguish `null`, the workflow isn't finished, from `[]`, the
     * workflow finished with no outputs.
     */
    outputs(): Promise<Env.Bindings<Value.Base> | null> {
        if (this.finished.size < this.jobs.size) {
            return Promise.resolve(null);
        }
        const ans = this.jobOutputs.get("outputs");
        if (!ans) {
            throw new Error("Missing outputs");
        }
        return Promise.resolve(ans);
    }

    async step(
        cfg: Loader,
        stdlib: StdLib.Base
    ): Promise<CallInstructions | null> {
        let runnable: string[] = [];
        while (true) {
            // select a job whose dependencies are all finished
            if (runnable.length === 0) {
                runnable = [...this.waiting]
                    .filter(j => {
                        const job = this.jobs.get(j);
                        if (!job) return false;
                        return [...job.dependencies].every(d => this.finished.has(d));
                    })
                    .sort()
                    .reverse();
            }
            if (runnable.length === 0) {
                if (!this.running.size && this.waiting.size) {
                    throw new Error("deadlocked: " + 
                        new Set(
                            [...this.waiting].flatMap(j => {
                                const job = this.jobs.get(j);
                                return job ? [...job.dependencies] : [];
                            })
                        ).difference(this.finished)
                    );
                }
                return null;
            }

            const jobId = runnable.pop()!;
            const job = this.jobs.get(jobId)!;

            // mark it 'running'
            this.running.add(job.id);
            this.waiting.delete(job.id);

            // do the job
            try {
                const res = await this._doJob(cfg, stdlib, job);
                if (this._isCallInstructions(res)) {
                    return res;
                }

                // otherwise, record the outputs, mark the job finished, and move on to the next job
                const envlog = this.valuesToJson(res);
                this.logger.info(
                    "visit", 
                    { 
                        node: job.id,
                        values: JSON.stringify(envlog).length < 4096 ? envlog : "(((large)))"
                    }
                );
                this.jobOutputs.set(job.id, res);
                this.running.delete(job.id);
                this.finished.add(job.id);

            } catch (exn) {
                if (exn instanceof Error) {
                    // (exn).jobId = job.id;
                }
                throw exn;
            }
        }
    }

    callFinished(jobId: string, outputs: Env.Bindings<Value.Base>): void {
        if (!this.running.has(jobId)) {
            throw new Error(`Job ${jobId} not running`);
        }

        const outlog = this.valuesToJson(outputs);
        this.logger.info("finish", { job: jobId });
        this.logger.info(
            "output",
            {
                job: jobId,
                values: JSON.stringify(outlog).length < 4096 ? outlog : "(((large)))"
            }
        );

        const job = this.jobs.get(jobId);
        if (!job) throw new Error(`Unknown job ${jobId}`);
        const callNode = job.node;
        if (!(callNode instanceof Tree.Call)) {
            throw new Error(`Job ${jobId} not a call`);
        }

        this.jobOutputs.set(jobId, outputs.wrapNamespace(callNode.name));
        this.fspathAllowlist = new Set([...this.fspathAllowlist, ..._fspaths(outputs)]);
        this.finished.add(jobId);
        this.running.delete(jobId);
    }

    private _schedule(job: Job): void {
        this.logger.debug("schedule", { 
            node: job.id, 
            dependencies: [...job.dependencies] 
        });
        if (this.jobs.has(job.id)) {
            throw new Error(`Duplicate job id: ${job.id}`);
        }
        this.jobs.set(job.id, job);
        this.waiting.add(job.id);
    }

    private async _doJob(
        cfg: Loader,
        stdlib: StdLib.Base,
        job: Job
    ): Promise<CallInstructions | Env.Bindings<Value.Base>> {
        if (job.node instanceof Tree.Gather) {
            const deps = Object.fromEntries(
                [...job.dependencies].map(id => [id, this.jobOutputs.get(id)!])
            );
            return _gather(job.node, deps);
        }

        // for all non-Gather nodes, derive the environment by merging the outputs of all the
        // dependencies (+ any current scatter variable bindings)
        let scatterVars: Env.Bindings<Value.Base> = new Env.Bindings();
        for (const p of job.scatterStack) {
            scatterVars = new Env.Bindings(p[1], scatterVars);
        }

        const depOutputs = [...job.dependencies].map(d => this.jobOutputs.get(d)!);
        const env = Env.merge(scatterVars, ...depOutputs);
        const envlog = this.valuesToJson(env);
        this.logger.debug(
            "env",
            {
                node: job.id,
                values: JSON.stringify(envlog).length < 4096 ? envlog : "(((large)))"
            }
        );

        if (job.node instanceof Tree.Scatter || job.node instanceof Tree.Conditional) {
            for (const newjob of _scatter(
                this.workflow,
                job.node,
                env,
                job.scatterStack,
                stdlib,
                cfg.getInt("scheduler", "scatter_tag_max")
            )) {
                this._schedule(newjob);
            }
            // the section node itself has no outputs, so return an empty env
            return new Env.Bindings();
        }

        if (job.node instanceof Tree.Decl) {
            // bind the value obtained either (i) from the workflow inputs or (ii) by evaluating
            // the expr
            let v: Value.Base | null = null;
            try {
                v = this.inputs.resolve(job.node.name);
            } catch (_e) {
                // Key not found
            }
            
            if (v === null) {
                if (job.node.expr) {
                    const rslt = await job.node.expr.eval(env,  stdlib)
                    v = rslt.coerce(job.node.type);
                } else {
                    if (!job.node.type.optional) {
                        throw new Error(`Non-optional declaration ${job.node.name} has no value or expression`);
                    }
                    v = new Value.Null();
                }
            }
            return new Env.Bindings(new Env.Binding(job.node.name, v));
        }

        if (job.node instanceof WorkflowOutputs) {
            return Value.rewriteEnvPaths(
                env,
                (v) => _checkPathAllowed(cfg, this.fspathAllowlist, "workflow output", v)
            );
        }

        if (job.node instanceof Tree.Call) {
            // evaluate input expressions
            const callName = job.node.name;
            let callInputs: Env.Bindings<Value.Base> = new Env.Bindings();
            
            for (const [name, expr] of Object.entries(job.node.inputs)) {
                const rslt = await expr.eval(env, stdlib )
                callInputs = callInputs.bind(name,rslt );
            }
            
            // check workflow inputs for additional inputs supplied to this call
            for (const b of this.inputs.enterNamespace(callName)) {
                callInputs = callInputs.bind(b.name, b.value);
            }

            // coerce inputs to required types
            if (!(job.node.callee instanceof Tree.Task || job.node.callee instanceof Tree.Workflow)) {
                throw new Error(`Invalid callee type for ${job.node.name}`);
            }

            const calleeInputs = job.node.callee.availableInputs;
            callInputs = callInputs.map(b => {
                if (!calleeInputs.hasBinding(b.name)) return b;
                
                const inputDecl = calleeInputs.get(b.name)!;
                const type = inputDecl.expr 
                    ? inputDecl.type.copy(true)
                    : inputDecl.type;
                
                return new Env.Binding(b.name, b.value.coerce(type));
            });

            callInputs = Value.rewriteEnvPaths(
                callInputs,
                (v) => _checkPathAllowed(cfg, this.fspathAllowlist, `call ${callName} input`, v)
            );

            // issue CallInstructions
            this.logger.info("ready", { 
                job: job.id, 
                callee: job.node.callee.name 
            });
            const inplog = this.valuesToJson(callInputs);
            this.logger.info(
                "input",
                {
                    job: job.id,
                    values: JSON.stringify(inplog).length < 4096 ? inplog : "(((large)))"
                }
            );

            return {
                id: job.id,
                callee: job.node.callee,
                inputs: callInputs
            };
        }

        throw new Error("Not implemented");
    }

    private _isCallInstructions(obj: any): obj is CallInstructions {
        return obj && typeof obj === 'object' && 
               'id' in obj && 'callee' in obj && 'inputs' in obj;
    }

    get logger(): Logger {
        if (!this._logger) {
            this._logger = logger
        }
        return this._logger;
    }

    toJSON(): Record<string, any> {
        const ans = { ...this };
        return ans;
    }
}
function* _scatter(
    workflow: Tree.Workflow,
    section: Tree.Scatter | Tree.Conditional,
    env: Env.Bindings<Value.Base>,
    scatterStack: Array<[string, Env.Binding<Value.Base>]>,
    stdlib: StdLib.Base,
    maxTag: number
): Generator<Job> {
    // Track job IDs for each body node ID
    const multiplex = new Map<string, Set<string>>();
    for (const bodyNode of section.body) {
        multiplex.set(bodyNode.workflowNodeId, new Set());
        if (bodyNode instanceof Tree.WorkflowSection) {
            for (const subgather of Object.values(bodyNode.gathers)) {
                multiplex.set(subgather.workflowNodeId, new Set());
            }
        }
    }

    // Evaluate scatter array or boolean condition
    const v = section.expr.eval(env, stdlib );
    let array: (Value.Base | null)[] = [];
    
    if (section instanceof Tree.Scatter) {
        if (!(v instanceof Value.WDLArray)) {
            throw new Error("Expected array value for scatter");
        }
        array = [...v.value];
    } else {
        if (!(v instanceof Value.Boolean)) {
            throw new Error("Expected boolean value for conditional");
        }
        if (v.value) {
            // condition is satisfied, so we'll "scatter" over a length-1 array
            array = [null];
        }
    }

    const digits = array.length > 1 ? Math.ceil(Math.log10(array.length)) : 1;

    // For each array element, schedule an instance of the body subgraph
    let lastScatterIndices: string[] | null = null;
    const scatterTags = _scatterTags(array, maxTag);

    for (let i = 0; i < array.length; i++) {
        const arrayI = array[i];
        
        // Scatter bookkeeping
        let scatterStackI = scatterStack;
        if (arrayI instanceof Value.Base) {
            if (!(section instanceof Tree.Scatter)) {
                throw new Error("Unexpected array value for conditional");
            }
            
            let strI = i.toString().padStart(digits, '0');
            if (strI.length > digits) {
                throw new Error(`Index string length exceeds digits: ${strI}`);
            }
            
            if (scatterTags[i]) {
                strI += "-" + scatterTags[i];
            }
            scatterStackI = [...scatterStackI, [strI, new Env.Binding(section.variable, arrayI)]];
        }
        
        const scatterIndicesI = scatterStackI.map(p => p[0]);
        if (lastScatterIndices !== null && !isLessThan(lastScatterIndices, scatterIndicesI)) {
            throw new Error("Scatter indices not in ascending order");
        }
        lastScatterIndices = scatterIndicesI;

        // Schedule each body (template) node
        for (const bodyNode of section.body) {
            if (scatterIndicesI.length !== bodyNode.scatterDepth) {
                throw new Error("Scatter depth mismatch");
            }
            
            const bodyJobId = _appendScatterIndices(bodyNode.workflowNodeId, scatterIndicesI);

            // Rewrite dependencies
            const dependencies = new Set<string>();
            for (const depId of bodyNode.workflowNodeDependencies) {
                const dep = workflow.getNode(depId);
                if (dep.scatterDepth > bodyNode.scatterDepth) {
                    throw new Error("Invalid dependency scatter depth");
                }
                dependencies.add(
                    _appendScatterIndices(depId, scatterIndicesI.slice(0, dep.scatterDepth))
                );
            }

            yield {
                id: bodyJobId,
                node: bodyNode,
                dependencies,
                scatterStack: scatterStackI
            };

            // Record scheduled job and expected gathers
            const bodyNodeJobs = multiplex.get(bodyNode.workflowNodeId);
            if (!bodyNodeJobs) {
                throw new Error(`Missing multiplex entry for ${bodyNode.workflowNodeId}`);
            }
            bodyNodeJobs.add(bodyJobId);

            if (bodyNode instanceof Tree.WorkflowSection) {
                for (const subgather of Object.values(bodyNode.gathers)) {
                    const subgatherJobs = multiplex.get(subgather.workflowNodeId);
                    if (!subgatherJobs) {
                        throw new Error(`Missing multiplex entry for ${subgather.workflowNodeId}`);
                    }
                    subgatherJobs.add(
                        _appendScatterIndices(subgather.workflowNodeId, scatterIndicesI)
                    );
                }
            }
        }
    }

    // Schedule gather operations
    for (const [bodyNodeId, gather] of Object.entries(section.gathers)) {
        yield {
            id: _appendScatterIndices(gather.workflowNodeId, scatterStack.map(p => p[0])),
            node: gather,
            dependencies: multiplex.get(bodyNodeId) || new Set(),
            scatterStack
        };
    }
}

function _appendScatterIndices(nodeId: string, scatterIndices: string[]): string {
    return [nodeId, ...scatterIndices].join("-");
}

function _scatterTags(array: (Value.Base | null)[], maxTag: number): string[] {
    // Given an array of values, compute array of names for each item for human readability
    let hasNonTrivialValues = false;
    const delimiters = /[^0-9a-zA-Z_]+/;
    const items: string[][] = array.map((arrayI, i) => {
        if (
            arrayI instanceof Value.Base &&
            !(arrayI instanceof Value.Null) &&
            !(arrayI instanceof Value.Int && arrayI.value === i)
        ) {
            hasNonTrivialValues = true;
            return JSON.stringify(arrayI.json).split(delimiters);
        }
        return [];
    });

    if (!hasNonTrivialValues || maxTag <= 0) {
        return array.map(() => "");
    }

    // Compute & remove longest common prefix & suffix
    const lcp = _longestCommonPrefix(items);
    const processedItems = lcp ? items.map(item => item.slice(lcp)) : items;
    
    const lcs = _longestCommonPrefix(processedItems.map(item => [...item].reverse()));
    const finalItems = lcs ? 
        processedItems.map(item => item.slice(0, -lcs)) : 
        processedItems;

    // Concatenate remaining components
    const tags = finalItems.map(item => item.join(""));

    // Try prefix truncation
    const tagsPfx = tags.map(tag => tag.slice(0, maxTag).replace(/-+$/, ""));
    if (isArrayUnique(tagsPfx.filter(t => t.length > 0))) {
        return tagsPfx;
    }

    // Try suffix if prefix didn't work
    const tagsSfx = tags.map(tag => tag.slice(-maxTag).replace(/^-+/, ""));
    return isArrayUnique(tagsSfx.filter(t => t.length > 0)) ?
        tagsSfx :
        array.map(() => "");
}

function isArrayUnique(arr: string[]): boolean {
    return arr.length === new Set(arr).size;
}

function isLessThan(a: string[], b: string[]): boolean {
    const minLength = Math.min(a.length, b.length);
    for (let i = 0; i < minLength; i++) {
        if (a[i] < b[i]) return true;
        if (a[i] > b[i]) return false;
    }
    return a.length < b.length;
}

function _longestCommonPrefix(items: string[][]): number {
    let ans = 0;
    for (let i = 0; i < items.length; i++) {
        const item = items[i];
        if (i === 0) {
            ans = item.length;
        } else {
            ans = Math.min(ans, item.length);
            const prevItem = items[i - 1];
            let j = 0;
            while (j < ans && item[j] === prevItem[j]) {
                j++;
            }
            ans = j;
        }
        if (ans === 0) {
            return 0;
        }
    }
    return ans;
}

function _gather(
    gather: Tree.Gather,
    dependencies: Record<string, Env.Bindings<Value.Base>>
): Env.Bindings<Value.Base> {
    // Important: dependency job IDs must sort lexicographically in desired array order!
    const depIds = Object.keys(dependencies).sort();

    // Verify ID order
    if (depIds.length > 1) {
        if (!(gather.section instanceof Tree.Scatter)) {
            throw new Error("Expected Scatter section for multiple dependencies");
        }
        const depIdsSplit = depIds.map(id => id.split("-"));
        const depIdLcp = _longestCommonPrefix(depIdsSplit);
        for (let i = 0; i < depIdsSplit.length; i++) {
            const depIdI = depIdsSplit[i];
            if (i !== parseInt(depIdI[depIdLcp])) {
                throw new Error("Dependency IDs not in expected order");
            }
        }
    }

    // Determine names of values to gather
    const leaf = gather.finalReferee;  // follow potential linked list of Gathers for nested sections
    let names: string[];
    if (leaf instanceof Tree.Decl) {
        names = [leaf.name];
    } else if (leaf instanceof Tree.Call) {
        const outp = leaf.effectiveOutputs.enterNamespace(leaf.name);
        if (outp.length !== leaf.effectiveOutputs.length) {
            throw new Error("Unexpected output length mismatch");
        }
        names = outp.mapToArray(b => b.name);
    } else {
        throw new Error("Unexpected leaf type");
    }

    // For each name, gather corresponding values
    let ans: Env.Bindings<Value.Base> = new Env.Bindings();
    const ns = leaf instanceof Tree.Call ? [leaf.name] : [];
    
    for (const name of names) {
        // Gather values
        const values = depIds.map(depId => 
            dependencies[depId].resolve(ns.concat([name]).join("."))
        );
        const v0 = values.length > 0 ? values[0] : null;
        
        if (v0 !== null && !(v0 instanceof Value.Base)) {
            throw new Error("Expected Value.Base type");
        }

        // Bind array, singleton value, or null as appropriate
        let rhs: Value.Base;
        if (gather.section instanceof Tree.Scatter) {
            rhs = new Value.WDLArray(v0 ? v0.type : new Type.Any(), values);
        } else {
            if (!(gather.section instanceof Tree.Conditional)) {
                throw new Error("Expected Conditional section");
            }
            if (values.length > 1) {
                throw new Error("Too many values for Conditional gather");
            }
            rhs = v0 ?? new Value.Null();
        }
        
        ans = ans.bind(ns.concat([name]).join("."), rhs);
    }

    return ans;
}

class _StdLib extends StdLib.Base {
    private cfg: Loader;
    private state: StateMachine;

    constructor(
        wdlVersion: string,
        cfg: Loader,
        state: StateMachine,
    ) {
        super(wdlVersion, path.join(state.runDir, "write_"));
        this.cfg = cfg;
        this.state = state;
    }

    protected _devirtualizeFilename(filename: string): string {
        return _checkPathAllowed(
            this.cfg,
            this.state.fspathAllowlist,
            "read_*() argument",
            new Value.File(filename)
        );
    }

    protected _virtualizeFilename(filename: string): string {
        // Handle written files at workflow level
        if (filename.endsWith("/")) {
            throw new Error("Directory handling not implemented"); // FIXME
        }
        this.state.fspathAllowlist.add(filename);
        return filename
        };
}

function _checkPathAllowed(
    cfg: Loader,
    allowlist: Set<string>,
    desc: string,
    v: Value.File | Value.Directory
): string {
    const isdir = v instanceof Value.Directory;
    const fspath = v.value.replace(/\/*$/, "") + (isdir ? "/" : "");
    if(allowlist.has(fspath)){// or downloadable(cfg, fspath, directory=isdir)){
       return v.value
    }
    if (!cfg.getBoolean("file_io", "allow_any_input")) {
        throw new WDLError.InputError(
            `${desc} uses file/directory not expressly supplied with workflow inputs` +
            " (to allow, set [file_io] allow_any_input = true): " + fspath
        );
    }

    // Validate path for allow_any_input
    const exists = isdir ? existsSync(fspath) : existsSync(fspath);
    if (!exists) {
        throw new WDLError.InputError(`${desc} uses nonexistent file/directory: ${fspath}`);
    }

    const abspath = path.resolve(fspath).replace(/\/*$/, "");
    if (!pathReallyWithin(abspath, cfg.get("file_io", "root"))) {
        throw new WDLError.InputError(
            `${desc} ${v.value} must reside within [file_io] root ${cfg.get("file_io", "root")}`
        );
    }

    return fspath;
}
interface RunOptions {
    runId?: string;
    runDir?: string;
    loggerPrefix?: string[];
    testPickle?: boolean;
    runIdStack?: string[];
}

/**
 * Run a workflow locally.
 * 
 * Inputs shall have been typechecked already. File inputs are presumed to be local POSIX file
 * paths that can be mounted into a container.
 */
export async function runLocalWorkflow(
    cfg: Loader,
    workflow: Tree.Workflow,
    inputs: Env.Bindings<Value.Base>,
    options: RunOptions = {}
): Promise<[string, Env.Bindings<Value.Base>]> {
    const {
        runId = workflow.name,
        runIdStack = [],
        loggerPrefix = ['wdl'],
    } = options;
    // Provision run directory and log file
    const runDir = await provisionRunDir(workflow.name, options.runDir, !runIdStack.length);

    const loggerId = [...loggerPrefix, `w:${runId}`];
    //const logfile = path.join(runDir, 'workflow.log');


        logger.info('workflow start', {
            name: workflow.name,
            source: workflow.pos.uri,
            line: workflow.pos.line,
            column: workflow.pos.column,
            dir: runDir
        });

        logger.debug('thread', { ident: Deno.pid });


        // Set up cache

        await writeValuesJson(inputs, path.join(runDir, 'inputs.json'), 
            workflow.name 
        );

        // Query call cache
        const cached = null//await cache.get(cacheKey, , workflow.effectiveOutputs);

        if (cached) {

            const _outputs = await linkOutputs(cached, runDir,
                cfg.getBoolean('file_io', 'output_hardlinks'),
                cfg.getBoolean('file_io', 'use_relative_output_paths')
            );

            await writeValuesJson(cached, path.join(runDir, 'outputs.json'),
                workflow.name
            );

            logger.info('done (cached)');
            // Return cached, not rewritten outputs, to retain opportunity to find cached downstream inputs
            return [runDir, cached];
        }


        try {
            // Run workflow state machine
            const outputs = await workflowMainLoop(
                cfg,
                workflow,
                inputs,
                [...runIdStack, runId],
                runDir,
                logger,
                loggerId,
            );

            return [runDir, outputs];

        } catch (error) {
            if (!runIdStack.length && cfg.getBoolean('scheduler', 'fail_fast')) {
                // Signal abort to anything still running if top-level workflow
                // process.kill(process.pid, 'SIGUSR1');
            }
            throw error;
        }
}

async function workflowMainLoop(
    cfg: Loader,
    workflow: Tree.Workflow,
    inputs: Env.Bindings<Value.Base>,
    runIdStack: string[],
    runDir: string,
    logger: Logger,
    loggerId: string[],
): Promise<Env.Bindings<Value.Base>> {
    // Start plugin coroutines

    // Download input files if needed
    await downloadInputFiles(
        cfg,
        logger,
        loggerId,
        runDir,
        addDownloadableDefaults(cfg, workflow.availableInputs, inputs)
    );

    // Run workflow state machine
    const state = new StateMachine(loggerId.join('.'), runDir, workflow, inputs);

    while (true) {
        const output = await state.outputs()
        if(output){
            break;
        }
        // Schedule all runnable calls
        const stdlib = new _StdLib(workflow.effectiveWdlVersion, cfg, state);
        let nextCall = await state.step(cfg, stdlib);

        while (nextCall) {
            const callDir = path.join(runDir, nextCall.id);
            if (existsSync(callDir)) {
                logger.warn('call subdirectory already exists, conflict likely', { 
                    dir: callDir 
                });
            }

            const subArgs = {
                cfg,
                callee: nextCall.callee,
                inputs: nextCall.inputs,
                options: {
                    runId: nextCall.id,
                    runDir: path.join(callDir, '.'),
                    loggerPrefix: loggerId,
                    runIdStack
                }
            };

            // Submit to appropriate thread pool
            const options = subArgs.options
            let future: [string, Env.Bindings<Value.Base>];
            if (nextCall.callee instanceof Tree.Task) {
                const options = subArgs.options
                future = await runLocalTask(subArgs.cfg,subArgs.callee as Tree.Task,subArgs.inputs,
                    options.runId,options.runDir,options.loggerPrefix,options.runIdStack);
            } else if (nextCall.callee instanceof Tree.Workflow) {
                future = await runLocalWorkflow(subArgs.cfg,subArgs.callee as Tree.Workflow,subArgs.inputs,subArgs.options)
            } else {
                throw new Error('Invalid callee type');
            }
            state.callFinished(nextCall.id,future[1])
            nextCall = await state.step(cfg, stdlib);
        }

        // Wait for an outstanding call to finish
    }
    const output = await state.outputs()
    if(!output){
        throw new Error("unexpected")
    }
    // Create output links
    const outputs = await linkOutputs(output, runDir,
        cfg.getBoolean('file_io', 'output_hardlinks'),
        cfg.getBoolean('file_io', 'use_relative_output_paths')
    );

    const finalOutputs = outputs//recv.value.outputs;

    warnOutputBasenameCollisions(logger, finalOutputs);

    // Write outputs.json
    await writeValuesJson(finalOutputs, path.join(runDir, 'outputs.json'),
        workflow.name
    );

    logger.info('done');
    return finalOutputs;
}
